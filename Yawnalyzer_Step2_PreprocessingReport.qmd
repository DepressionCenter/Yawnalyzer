---
title: "Yawnalyzer"
subtitle: "Preprocessing Report"
date: last-modified
date-format: "[Last Modified:] DD MMM YYYY"
license: "GPL-3.0-or-later"
copyright:
    holder: "The Regents of the University of Michigan"
    year: 2025
rights: |
    © 2025 The Regents of the University of Michigan.
    
    This file is part of Yawnalyzer.
    
    Yawnalyzer is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.
format:
    html:
        toc: true
        toc-depth: 3
        code-fold: true
        df-print: paged
        embed-resources: true
        html-math-method: mathjax
jupyter: python3
---

```{python}

#| tags: [parameters]
#| echo: false
#| message:
#| code-fold: false

RID = "PARTICIPANT_ID"

```

```{python}

#| label: "Import_Packages" 
#| echo: false
#| message:
#| code-fold: false

import os
import pandas as pd
import numpy as np
#import neurokit2 as nk
import plotly.express as px
import plotly.graph_objects as go
import datetime as dt
from datetime import datetime, timedelta
from IPython.display import Markdown, display
import session_info
import copy
import PathKeeper

```

# About this Report

```{python}

#| label: ParticipantID
#| code-hide: true
#| echo: false



Markdown(f"> Participant: _**{RID}**_")

```

> Generation Date: `{python} dt.datetime.now().strftime("%Y-%m-%d")`

This is a processing report for Subject ID (SID) **`{python} RID`** from the MS-EMA project (IRB #HUM00265263; PI: Tiffany Braley, MD). MS-EMA is an Apple watch-based sleep tracking study conducted with patients with Multiple Sclerosis.

This report provides both a sense of quality and summary metrics for the following types of information:

-   Heart rate (derived from PPG)
-   Sleep-related metrics
-   Gait and balance

Data for the above were collected over the span of approximately 12 weeks for each subject. Plots contained within this report are summarized by week.

```{python}

#| label: "Functions"
#| echo: false
#| warning: false
#| message: false

def prettify_info(df, memory_usage=False, deep=True, sort_by_nulls=False, show_unique=True, show_stats=True):
  n=len(df)
  info_df=pd.DataFrame({
    
    "Column":df.columns,
    "Total Count" : df.count(),
    "Not-Nulls Count" : df.notnull().sum(),
    "Missing Count" : df.isnull().sum(),
    "Type" : df.dtypes.astype(str)
    })
  if show_unique:
    info_df["Unique Count"] = df.nunique(dropna=True)
  
  if show_stats:
    numeric_cols = df.select_dtypes(include=[np.number])

    sum_stats_dictionary ={
        "Means" : numeric_cols.mean(),#.round(5)
        "Median" : numeric_cols.median(),#.round(5)
        "Standard Deviation" : numeric_cols.std(),#.round(5)
        "Min": numeric_cols.min(),
        "25%": numeric_cols.quantile(0.25),
        "75%": numeric_cols.quantile(0.75),
        "Max": numeric_cols.max()
    }

    for stat_name, stat_values in sum_stats_dictionary.items():
        valid_numeric_cols = set(stat_values.index)

        info_df[stat_name] = info_df["Column"].apply(
            lambda col: stat_values[col] if col in valid_numeric_cols else " "
        )

  base_cols = ["Total Count","Not-Nulls Count","Missing Count"]
  uniqueness_cols = ["Unique Count"] if show_unique else []
  stat_cols = list(sum_stats_dictionary.keys()) if show_stats else []
  info_df = info_df[base_cols + uniqueness_cols + stat_cols + ["Type"]]

  if memory_usage:
    mem = df.memory_usage(deep=deep).sum / 1024**2
    print(f"Memory usage: {mem.df} MB")

  
  return info_df

```

```{python}

#| label: "Inital-Read"
#| echo: false
#| warning: false
#| message: false

presence_df = pd.read_csv(os.path.join(PathKeeper.data_log_path,"Data_Presence_Log.csv"))

hr_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path,"hr_collapsed.csv"), index_col=["index_1"], dtype={
  "ID": "string",
  "submission_date": "string",
  "file_type": "string",
  "HR": "float64",
  "Timestamp":  "float64",
  "filename": "string" 
 }
)

sleep_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path,"sleep_collapsed.csv"), index_col=["index_1"])

gait_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path,"gait_collapsed.csv"), index_col=["index_1"])

double_support_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path,"double_support_collapsed.csv"), index_col=["index_1"])

asymmetry_df =pd.read_csv(os.path.join(PathKeeper.merged_data_path,"asymmetry_collapsed.csv"), index_col=["index_1"])

fatigue_survey_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path, "fatigue_survey_collapsed.csv"), index_col=["index_1"]
)

cognitive_survey_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path, "cog_collapsed.csv"), index_col=["index_1"]
)

sleep_survey_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path, "sleep_survey_collapsed.csv"), index_col=["index_1"]
)

hr_df = hr_df[hr_df["ID"] == RID].copy()
sleep_df = sleep_df[sleep_df["ID"] == RID].copy()
gait_df = gait_df[gait_df["ID"] == RID].copy()
double_support_df = double_support_df[double_support_df["ID"] == RID].copy()
asymmetry_df = asymmetry_df[asymmetry_df["ID"] == RID].copy()
sleep_survey_df = sleep_survey_df[sleep_survey_df["ID"] == RID].copy()
cognitive_survey_df = cognitive_survey_df[cognitive_survey_df["ID"] == RID].copy()
fatigue_survey_df = fatigue_survey_df[fatigue_survey_df["ID"] == RID].copy()

all_surveys_df = sleep_survey_df.drop("Question4", axis=1).merge(cognitive_survey_df, how="outer")

all_surveys_df = all_surveys_df.merge(fatigue_survey_df.drop("Question4", axis=1), how="outer")

all_surveys_df["Sleep03"] = all_surveys_df["Sleep03"].str.strip().replace("Sleep03: No new symptoms","Sleep03: 0 = No new symptoms")

if "all_surveys_df" in locals() and len(all_surveys_df) >0:
    all_surveys_df[["survey_date", "survey_type"]] = all_surveys_df["Survey"].str.rsplit("_", n=1, expand=True)

cols = ['Sleep01', 'Sleep02', 'Sleep03', 'Cognitive01','Cognitive02', "Pain",'Depression', 'Physical_Fatigue', 'Brain_Fatigue', 'Sleepiness']


for c in cols:
    col_as_series = all_surveys_df[c].fillna("").astype(str)
    non_missing_index = col_as_series.str.contains(":")
    non_missing_series = col_as_series.str.split(":", n=1, expand=True)
    non_missing_df = non_missing_series.reindex(columns=[0,1])
    non_missing_df = non_missing_df.apply(lambda col: col.str.strip())

    all_surveys_df[f"{c}_question"] = np.where(
        non_missing_index,
        non_missing_df[0],
        f"{c}_question"
    )  

    all_surveys_df[f"{c}_value"] = np.where(
        non_missing_index,
        non_missing_df[1],
        np.nan
    )
    
    all_surveys_df[f"{c}_value"] = ( all_surveys_df[f"{c}_value"].astype(str).str.extract(r"(\d+)").astype("Int64"))

all_surveys_df = all_surveys_df.drop(['Sleep01', 'Sleep02', 'Sleep03', 'Cognitive01','Cognitive02','Pain','Depression', 'Physical_Fatigue', 'Brain_Fatigue', 'Sleepiness'], axis=1)

cols_to_drop = [col for col in all_surveys_df.columns if "_question" in col]

all_surveys_df = all_surveys_df.drop(columns=cols_to_drop)
all_surveys_df.columns = all_surveys_df.columns.str.replace("_value","")

if "all_surveys_df" in locals() and len(all_surveys_df) >0:
    cognitive_survey_df = all_surveys_df[all_surveys_df["survey_type"] == "Cognitive"].dropna(axis=1, how="all").drop(columns=["survey_type"])

    fatigue_survey_df = all_surveys_df[all_surveys_df["survey_type"] == "Fatigue"].dropna(axis=1, how="all").drop(columns=["survey_type"])

    sleep_survey_df  = all_surveys_df[all_surveys_df["survey_type"] == "Sleep"].dropna(axis=1, how="all").drop(columns=["survey_type"])

has_hr ="hr_df" in locals() and len(hr_df) > 0

has_sleep ="sleep_df" in locals() and len(sleep_df) > 0

has_gait ="gait_df" in locals() and len(gait_df) > 0

has_double_support ="double_support_df" in locals() and len(double_support_df) > 0

has_asymmetry= "asymmetry_df" in locals() and len(asymmetry_df) > 0

has_cognitive_survey= "cognitive_survey_df" in locals() and len(cognitive_survey_df) > 0
has_fatigue_survey= "fatigue_survey_df" in locals() and len(fatigue_survey_df) > 0
has_sleep_survey= "sleep_survey_df" in locals() and len(sleep_survey_df) > 0

overall_summary = {}

overall_summary["ID"] =  RID;

del non_missing_df, non_missing_index, non_missing_series, col_as_series, cols, cols_to_drop, c
```

```{python}

#| label: "Time-Conversions"
#| eval: True
#| echo: false
#| warning: false
#| message: false

#Sleep 

sleep_df["StartISO"] = pd.to_datetime(sleep_df["StartISO"], utc=True).dt.tz_convert(
    "America/Detroit"
)

sleep_df["EndISO"] = pd.to_datetime(sleep_df["EndISO"], utc=True).dt.tz_convert(
    "America/Detroit"
)

sleep_df["StartISO"] = (
    sleep_df["StartISO"]
    .infer_objects()
    .fillna(pd.to_datetime(sleep_df["Start"], unit="s", utc=True))
)

sleep_df["EndISO"] = (
    sleep_df["EndISO"]
    .infer_objects()
    .fillna(pd.to_datetime(sleep_df["End"], unit="s", utc=True))
)

sleep_df = sleep_df.sort_values(by="StartISO")

sleep_df["gap_seconds"]  = (
    sleep_df.groupby("ID")["EndISO"].shift().rsub(sleep_df["StartISO"]).dt.total_seconds()
    )
sleep_df["gap_hours"] = (sleep_df["gap_seconds"]/3600) 

sleep_df["Session"] = sleep_df["gap_hours"].isna() | (sleep_df["gap_hours"] >=2)

sleep_df["session_id"] = sleep_df["Session"].cumsum()

sleep_df = (
    sleep_df.groupby(["session_id",'ID', 'submission_date', 'file_type', 'filename']).agg(
        ID = ("ID", "first"),
        submission_date = ('submission_date', "first"), 
        file_type = ('file_type',"first"),
        filename=('filename', 'first'),
        StartISO =('StartISO', "min"),
        EndISO = ('EndISO', "max"),
        Start = ('Start', "min"),
        End = ('End', "max")
    )
    .reset_index(drop=True)
)

sleep_df["Duration"] = sleep_df["EndISO"] - sleep_df["StartISO"]
sleep_df["Duration_in_Minutes"] = sleep_df["Duration"].dt.total_seconds()/60

sleep_df["hour"] = sleep_df["EndISO"].dt.hour

sleep_df["Before_or_After_noon"] = np.where(sleep_df["EndISO"].dt.hour < 12,"Morning","Afternoon")

sleep_df["Night_of_Sleep"] = np.where(
    sleep_df["Before_or_After_noon"] == "Morning",
    (sleep_df["EndISO"] - pd.Timedelta(days=1)).dt.date,
    sleep_df["EndISO"].dt.date,
)

sleep_df["Duration_in_Minutes"] = sleep_df["Duration_in_Minutes"].where(
    sleep_df["Duration_in_Minutes"] <= (24*60), #24 hours of 60 minutes
)

sleep_df["Night_of_Sleep"] = sleep_df["Night_of_Sleep"].where(
    sleep_df["Duration_in_Minutes"].notna()
)


sleep_df["Night_of_Sleep"] = pd.to_datetime(
    sleep_df["Night_of_Sleep"], utc=True,
    errors="coerce").dt.tz_convert("America/Detroit").dt.date

#sleep_df["Night_of_Sleep"] = sleep_df["Night_of_Sleep"].dt.date

sleep_df["EndISO"] = (
    sleep_df["EndISO"]
    .infer_objects()
    .fillna(pd.to_datetime(sleep_df["End"], unit="s", utc=True))
)

sleep_df=sleep_df.drop(["hour","Before_or_After_noon","Duration"], axis=1)


#Heart Rate

hr_df["TimestampISO"] = pd.to_datetime(hr_df["TimestampISO"],errors="coerce", utc=True)


hr_df["TimestampISO"] = (
    hr_df["TimestampISO"]
    .infer_objects()
    .fillna(pd.to_datetime(hr_df["Timestamp"], unit="s", utc=True))
)

hr_df["TimestampISO"] = (
    pd.to_datetime(hr_df["TimestampISO"], utc=True, errors="coerce")
    .dt.tz_convert("America/Detroit")
    .infer_objects()
)   

# Gait
gait_df["TimestampISO"] = pd.to_datetime(gait_df["TimestampISO"], utc=False)

gait_df["TimestampISO"] = (
    gait_df["TimestampISO"]
    .infer_objects()
    .fillna(pd.to_datetime(gait_df["Timestamp"], unit="s", utc=True).dt.tz_convert("America/Detroit"))
)
# Double Support
double_support_df["TimestampISO"] = pd.to_datetime(double_support_df["TimestampISO"], utc=False)

double_support_df["TimestampISO"] = (
    double_support_df["TimestampISO"]
    .infer_objects()
    .fillna(pd.to_datetime(double_support_df["Timestamp"], unit="s", utc=True).dt.tz_convert("America/Detroit"))
)
# Asymmetry

asymmetry_df["TimestampISO"] = pd.to_datetime(asymmetry_df["TimestampISO"], utc=False)

asymmetry_df["TimestampISO"] = (
    asymmetry_df["TimestampISO"]
    .infer_objects()
    .fillna(pd.to_datetime(asymmetry_df["Timestamp"], unit="s", utc=True).dt.tz_convert("America/Detroit"))
)
# Cognitive survey

cognitive_survey_df["Timestamp"] = pd.to_datetime(cognitive_survey_df["Timestamp"],errors="coerce", utc=True).dt.tz_convert(
    "America/Detroit"
)

# Fatigue survey

fatigue_survey_df["Timestamp"] = pd.to_datetime(fatigue_survey_df["Timestamp"],errors="coerce", utc=True).dt.tz_convert(
    "America/Detroit"
)

# Sleep survey

sleep_survey_df["Timestamp"] = pd.to_datetime(sleep_survey_df["Timestamp"],errors="coerce", utc=True).dt.tz_convert(
    "America/Detroit"
)



```

```{python}
#|label: Sort dataframes by Time
#| echo: false
#| warning: false
#| message: false

hr_df=hr_df.sort_values(by="TimestampISO")
sleep_df = sleep_df.sort_values(by="StartISO")
gait_df = gait_df.sort_values(by="TimestampISO")
double_support_df = double_support_df.sort_values("TimestampISO")
asymmetry_df = asymmetry_df.sort_values("TimestampISO")
cognitive_survey_df = cognitive_survey_df.sort_values("Timestamp")
fatigue_survey_df = fatigue_survey_df.sort_values("Timestamp") 
sleep_survey_df = sleep_survey_df.sort_values("Timestamp")

```

# Heart Rate

## General Information

```{python}

#| label: Prettify_HR_Table
#| echo: false
#| warning: false
#| message: false

if has_hr:
    display(prettify_info(hr_df))
else:
    display(Markdown(f"_**No Heart Rate Data Exists**_"))

```

## Plotting

```{python}

#| label: HR_Plot
#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_hr:
    hr_sorted_df = hr_df.sort_values(by="TimestampISO")
    hr_sorted_df["Time_Averaged_Over"] = hr_sorted_df.sort_values(["ID","TimestampISO"]).groupby("ID")["TimestampISO"].diff()
    hr_sorted_df["Time_Averaged_Over_in_Minutes"] =  hr_sorted_df["Time_Averaged_Over"].dt.total_seconds()/60

    hr_fig = go.Figure()

    hr_fig.add_trace(
    go.Scatter(
        x=hr_sorted_df["TimestampISO"],
        y=hr_sorted_df["HR"],
        mode="lines+markers",
        marker=dict(
        color="red"
        ),
        line=dict(
        color="green",
        width=1
        )
    )
    )

    # fig = px.line(
    #   x=q["TimestampISO"],
    #   y=q["HR"],
    #   markers=True
    #   )
    # fig.update_traces(
    #   line_color="red",
    # )
    hr_fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )
    hr_fig.show()
else:
    display(Markdown(f"_**No Heart Rate Data Exists**_"))

```

### Time Mean HR calculated Over

```{python}
if has_hr:
    hr_gap_df = hr_sorted_df.sort_values("Time_Averaged_Over_in_Minutes")
    #hr_histogram_df = hr_histogram_df.tips()

    hr_box_fig =px.box(hr_gap_df, y="Time_Averaged_Over_in_Minutes", x="ID",  title="Distribution of Distances between HR recordings in Minutes")

    hr_box_fig.show()

    hr_hist_fig = px.histogram(hr_gap_df, x="Time_Averaged_Over_in_Minutes", title="Histogram of Time Difference between HR recordings in Minutes")

    hr_hist_fig.show()
else:
    display(Markdown(f"_**No Heart Rate Data Exists**_"))
```

# Sleeping

## General Information

```{python}
#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_sleep:
    display(prettify_info(sleep_df))
else:
    display(Markdown(f"_**No Sleep Data Exists**_"))
    # with open("MissingSleep.txt", "r") as file:
    # content = file.read()
    # print(content)

```

## Plotting

Below is a stacked bargraph. Each bar on the x-axis represents a different potential night of sleep that occurred between the start and end of their participation. If they had multiple sleep sessison for a given night of sleep, each session is a different color, and are stacked.

The y-axis ths the duration of the recorded sleep session in minutes.

The blue line represents 8 hours of sleep.

```{python}

#| label: Sleep_Duration_Plot
#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_sleep:
    sleep_temp_df = sleep_df.sort_values(by="Night_of_Sleep")
    sleep_temp_df['Sleep Session'] = sleep_temp_df.groupby('Night_of_Sleep').cumcount()
    sleep_temp_df["Sleep Session"] = "Sleep Session: " + (sleep_temp_df["Sleep Session"]+1).astype(str) 

    sleep_fig = go.Figure()
    sleep_fig.add_hline(y=(60*8), line_dash="dash", line_color="cyan", layer='below')

    for session in sleep_temp_df["Sleep Session"].unique():
        filtered_df = sleep_temp_df[sleep_temp_df["Sleep Session"] == session]

        sleep_fig.add_trace(
            go.Bar(
                x=filtered_df["Night_of_Sleep"],
                y=filtered_df["Duration_in_Minutes"],
                name=session     # ← now a proper string label
            )
        )
    sleep_fig.update_layout(
        xaxis_title = "Night of Sleep",
        yaxis_title = "Duration of Sleep (in Minutes)",
        barmode="stack",
        showlegend=False
    )

    sleep_fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )
    sleep_fig.show()
else:
    display(Markdown(f"_**No Sleep Data Exists**_"))


```

## Number of Consecutive 

# Gait and Walking Metrics

## Gait

### General Information

```{python}
#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_gait:
    display(prettify_info(gait_df))
else:
    display(Markdown(f"_**No Gait Data Exists**_"))

```

### Plot

```{python}
#| eval: true
#| echo: false
#| warning: false
#| message: false


if has_gait:
    gait_df["TimestampISO"] = (
    pd.to_datetime(gait_df["TimestampISO"], utc=True, errors="coerce")
    .dt.tz_convert("America/Detroit")
    .infer_objects()
)   

    gait_sorted_df = gait_df.sort_values(by="TimestampISO")

    gait_sorted_df["Balance"] = gait_sorted_df["Balance"]*100 

    gait_fig = go.Figure()

    gait_fig.add_trace(
    go.Scatter(
        x=gait_sorted_df["TimestampISO"],
        y=gait_sorted_df["Balance"],
        mode="lines+markers",
        marker=dict(
        color="orange"
        ),
        line=dict(
        color="green",
        width=1
        )
    )
    )

    # fig = px.line(
    #   x=q["TimestampISO"],
    #   y=q["HR"],
    #   markers=True
    #   )
    # fig.update_traces(
    #   line_color="red",
    # )
    gait_fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )
    gait_fig.add_hline(y=50, line_dash="dash", line_color="green", annotation_text="Balanced Gait")
    gait_fig.show()
else:
    display(Markdown(f"_**No Gait Data Exists**_"))
```

## Double Support

### General Information

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_double_support:
    display(prettify_info(double_support_df))
else:
    display(Markdown(f"_**No Double Support Data Exists**_"))

```

### Plot

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_double_support:
    double_support_sorted_df = double_support_df.sort_values(by="TimestampISO")
    double_support_sorted_df["Percentage"] = double_support_sorted_df["Percentage"]*100 

    double_support_fig = go.Figure()

    double_support_fig.add_trace(
    go.Scatter(
        x=double_support_sorted_df["TimestampISO"],
        y=double_support_sorted_df["Percentage"],
        mode="lines+markers",
        marker=dict(
        color="blue"
        ),
        line=dict(
        color="green",
        width=1
        )
    )
    )

    double_support_fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )
    double_support_fig.show()

else:
    display(Markdown(f"_**No Double Support Data Exists**_"))
```

# Surveys

## Cognitive

### General Information

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_cognitive_survey:
    display(prettify_info(cognitive_survey_df))
else:
    display(Markdown(f"_**No Cognitive Survey Responses Exists**_"))

```

### Plotting

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false
if has_cognitive_survey:
    cognitive_survey_long_df = cognitive_survey_df.melt(id_vars=["ID","survey_date", "Timestamp"], value_vars=["Cognitive01","Cognitive02","Pain", "Depression"], var_name='Questions', value_name='Value')

    cognitive_survey_long_df["survey_date"] = (
        pd.to_datetime(cognitive_survey_long_df["survey_date"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/New_York")
    )

####


    cognitive_survey_long_df = cognitive_survey_long_df.sort_values(["survey_date", "Timestamp"])
    
    cog_fig = px.line(
        cognitive_survey_long_df,
        x="survey_date",
        y="Value",
        color="Questions",
        facet_row="Questions",
        markers=True
    )
    cog_fig.for_each_annotation(
    lambda a: a.update(text=a.text.split("=")[-1])
    
    )

    # 1. Match all x-axes
    cog_fig.update_xaxes(matches="x")

    # 2. Disable sliders everywhere
    cog_fig.update_xaxes(rangeslider_visible=False)

    # 3. Enable slider ONLY on the bottom x-axis
    bottom_xaxis = min(
        cog_fig.select_xaxes(),
        key=lambda ax: ax.domain[0]
    )
    bottom_xaxis.rangeslider.visible = True
    cog_fig.update_layout(showlegend=False)


    cog_fig.show()
else:
    display(Markdown(f"_**No Cognitvie Survey Data Exists**_"))
```

## Fatigue

### General Information

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_fatigue_survey:
    display(prettify_info(fatigue_survey_df))
else:
    display(Markdown(f"_**No Fatigue Survey Responses Exists**_"))

```

### Plotting

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false
if has_fatigue_survey:
    fatigue_survey_long_df = fatigue_survey_df.melt(id_vars=["ID","survey_date", "Timestamp"], value_vars=[ 'Physical_Fatigue', 'Brain_Fatigue', 'Sleepiness'], var_name='Questions', value_name='Value')

    fatigue_survey_long_df["survey_date"] = (
        pd.to_datetime(fatigue_survey_long_df["survey_date"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/New_York")
    )

####


    fatigue_survey_long_df=fatigue_survey_long_df.sort_values(["survey_date", "Timestamp"])
    fatigue_fig = px.line(
        fatigue_survey_long_df,
        x="survey_date",
        y="Value",
        color="Questions",
        facet_row="Questions",
        markers=True,
    )
    fatigue_fig.for_each_annotation(
    lambda a: a.update(text=a.text.split("=")[-1])
    
    )
    
    fatigue_fig.update_xaxes(matches="x")

    # 2. Disable sliders everywhere
    fatigue_fig.update_xaxes(rangeslider_visible=False)

    # 3. Enable slider ONLY on the bottom x-axis
    bottom_xaxis = min(
        fatigue_fig.select_xaxes(),
        key=lambda ax: ax.domain[0]
    )
    fatigue_fig.update_layout(showlegend=False)

    bottom_xaxis.rangeslider.visible = True


    fatigue_fig.show()
else:
    display(Markdown(f"_**No Fatigue Survey Data Exists**_"))
```

## Sleepiness

### General Information

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_sleep_survey:
    display(prettify_info(fatigue_survey_df))
else:
    display(Markdown(f"_**No Sleep Survey Responses Exists**_"))

```

### Plotting

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false
if has_sleep_survey:
    sleep_survey_long_df = sleep_survey_df.melt(id_vars=["ID","survey_date", "Timestamp"], value_vars=[ 'Sleep01', 'Sleep02', 'Sleep03'], var_name='Questions', value_name='Value')

    sleep_survey_long_df["survey_date"] = (
        pd.to_datetime(sleep_survey_long_df["survey_date"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/New_York")
    )


####
    sleep_survey_long_df=sleep_survey_long_df.sort_values(["survey_date", "Timestamp"])
    sleepy_fig = px.line(
        sleep_survey_long_df,
        x="survey_date",
        y="Value",
        color="Questions",
        facet_row="Questions",
        markers=True,
    )
    sleepy_fig.for_each_annotation(
    lambda a: a.update(text=a.text.split("=")[-1])
    
    )
    
    sleepy_fig.update_xaxes(matches="x")

    # 2. Disable sliders everywhere
    sleepy_fig.update_xaxes(rangeslider_visible=False)

    # 3. Enable slider ONLY on the bottom x-axis
    bottom_xaxis = min(
        sleepy_fig.select_xaxes(),
        key=lambda ax: ax.domain[0]
    )
    sleepy_fig.update_layout(showlegend=False)

    bottom_xaxis.rangeslider.visible = True


    sleepy_fig.show()
else:
    display(Markdown(f"_**No Sleep Survey Data Exists**_"))
```

# Merge All data

```{python}
# | label: Generate merged HR and Sleep dataframe
# | eval: True
# | echo: false
# | warning: false
# | message: false

all_surveys_long_df = (pd.concat(
    [cognitive_survey_long_df, fatigue_survey_long_df, sleep_survey_long_df],
    ignore_index=True,
).sort_values(["survey_date", "Timestamp"]).reset_index(drop=True)
)
earliest_time = min(
    hr_df["TimestampISO"].min(),
    sleep_df["StartISO"].min(),
    gait_sorted_df["TimestampISO"].min(),
    double_support_sorted_df["TimestampISO"].min(),
    all_surveys_long_df["Timestamp"].min(),
)
latest_time = max(
    hr_df["TimestampISO"].max(),
    sleep_df["StartISO"].max(),
    gait_sorted_df["TimestampISO"].max(),
    double_support_sorted_df["TimestampISO"].max(),
    all_surveys_long_df["Timestamp"].max(),
)
time_df = pd.DataFrame(
    {
        "GlobalTime": pd.date_range(start=earliest_time, end=latest_time, freq="30s"),
        "Asleep": "0",
    }
)

mask = time_df["GlobalTime"].apply(
    lambda time: ((sleep_df["StartISO"] <= time) & (sleep_df["EndISO"] >= time)).any()
)

time_df["Asleep"] = mask.astype(int)
time_sorted_df = time_df.sort_values("GlobalTime")
hr_sorted_df = hr_df.sort_values("TimestampISO")

merge_df = pd.merge_asof(
    time_sorted_df,
    hr_sorted_df,
    left_on="GlobalTime",
    right_on="TimestampISO",
    direction="nearest",
    tolerance=pd.Timedelta(seconds=15),
)

new_order = merge_df[["ID", "GlobalTime", "Asleep", "HR"]]

merge_df2 = pd.merge_asof(
    new_order,
    gait_sorted_df[["TimestampISO", "Balance"]],
    left_on="GlobalTime",
    right_on="TimestampISO",
    direction="nearest",
    tolerance=pd.Timedelta(seconds=15),
).drop(columns=["TimestampISO"])

merge_df3 = pd.merge_asof(
    merge_df2,
    double_support_sorted_df[["TimestampISO", "Percentage"]],
    left_on="GlobalTime",
    right_on="TimestampISO",
    direction="nearest",
    tolerance=pd.Timedelta(seconds=15),
)


merge_df4 = pd.merge_asof(
    merge_df3,
    all_surveys_long_df.sort_values("Timestamp"),
    left_on="GlobalTime",
    right_on="Timestamp",
    direction="nearest",
    tolerance=pd.Timedelta(seconds=15),
)

all_data_df = merge_df4.drop(columns=["ID_y"]).rename(columns={"ID_x":"ID"})

all_data_df["ID"] = all_data_df["ID"].ffill().bfill()

```

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

IDs = []
night = []
start = []
end = []
average_hr = []
sd_hr = []
earliest_hr =[]
latest_hr =[]
earliest_timestamp=[]
latest_timestamp = []

for index, _ in sleep_df.iterrows():
    ID = sleep_df["ID"][index]
    start_time  = sleep_df["StartISO"][index]
    end_time  = sleep_df["EndISO"][index]
    sleep_day = sleep_df["Night_of_Sleep"][index]
    IDs.append(ID)
    start.append(start_time)
    end.append(end_time)
    night.append(sleep_day)
    #Filter hr_sorted_df to only be included between the start and stop times
    timing_df = hr_sorted_df[(hr_sorted_df["TimestampISO"] >= start_time)]
    timing_df = timing_df[(timing_df["TimestampISO"] <= end_time)]
    
    #Calculate the Mean and standard deviation of the Heart rate during this period (if any heart rate is recorded)
    aveHR = timing_df["HR"].mean()
    std_hr = timing_df["HR"].std()
    
    if len(timing_df) >0:
        first_hr_timestamp = timing_df["TimestampISO"].iloc[0]
        last_hr_timestamp = timing_df["TimestampISO"].iloc[-1]
        first_hr = timing_df["HR"].iloc[0]
        last_hr = timing_df["HR"].iloc[-1]
    else:
        first_hr_timestamp = np.nan
        last_hr_timestamp = np.nan
        first_hr = np.nan
        last_hr = np.nan

    average_hr.append(aveHR)
    sd_hr.append(std_hr)
    earliest_hr.append(first_hr)
    latest_hr.append(last_hr)
    earliest_timestamp.append(first_hr_timestamp)
    latest_timestamp.append(last_hr_timestamp)
    del timing_df
    

hr_dictionary = {
    'ID': IDs,
    'Night_of_Sleep': night,
    'Start_Time': start,
    'End_Time': end,
    'Mean_HR_Present_During_Period':average_hr,
    'Standard_Deviation_of_Present_HR_During Period': sd_hr,
    'Earliest_Recorded_HR': earliest_hr,
    'Earliest_Recorded_HR_Timestamp':earliest_timestamp,
    'Latest_Recorded_HR': latest_hr,
    'Latest_Recorded_HR_Timestamp': latest_timestamp,
}

HR_summary_df = pd.DataFrame(hr_dictionary)

if len(HR_summary_df) <=0:
    empty_row= pd.DataFrame([[pd.NA]*len(HR_summary_df.columns)], columns=HR_summary_df.columns)
    empty_row["ID"] = RID


csv_name = "HR_Summary_"+RID+".csv"

HR_summary_df.dropna(subset=["Night_of_Sleep"]).to_csv(os.path.join(PathKeeper.summarized_data_path,csv_name), index=False)
```

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

earliest_day =  sleep_df["Night_of_Sleep"].min()
latest_day = sleep_df["Night_of_Sleep"].max()

sleep_days_df = pd.DataFrame({
    "GlobalDay": pd.date_range(
        start=earliest_day,
        end=latest_day,
        freq="1D"
    )
}
)

sleep_df2 = sleep_df.dropna(subset=["Night_of_Sleep"]).copy()

sleep_df2["Night_of_Sleep"] = pd.to_datetime(sleep_df["Night_of_Sleep"])

sleep_all_df = pd.merge(sleep_days_df, sleep_df2, left_on="GlobalDay", right_on="Night_of_Sleep", how="left").sort_values(["GlobalDay", "StartISO"])

sleep_all_df["ID"] = sleep_all_df["ID"].fillna(RID)

sleep_summary_df = pd.DataFrame()

for date, dataframe in sleep_all_df.groupby("GlobalDay"):
    if dataframe["Duration_in_Minutes"].isna().all():
        dataframe["Asleep_Time"] = pd.NA
        dataframe["AwakeTime"] = pd.NA
        dataframe["Date"] = date
    else:
        dataframe["Asleep_Time"] = dataframe["Duration_in_Minutes"].sum()
        dataframe["Awake_Time"] =  (24*60) -dataframe["Asleep_Time"]
        dataframe["Date"] = date
    sleep_summary_df = pd.concat([sleep_summary_df, dataframe], ignore_index=True) 

sleep_summary_df = sleep_summary_df[["ID", "GlobalDay", "Asleep_Time", "Awake_Time"]].drop_duplicates("GlobalDay").rename(columns={"GlobalDay":"Day_of_Sleep"})


sleep_summary_df["Day_of_Sleep"] = pd.to_datetime(sleep_summary_df["Day_of_Sleep"]).dt.date


sleep_present = sleep_summary_df["Asleep_Time"].notna()

# Each missing value increases the GroupID
sleep_summary_df["streak_id"] = (~sleep_present).groupby(sleep_summary_df["ID"]).cumsum()

# Count number of day that each day is for a given "streak"
sleep_summary_df["Streak_Length"] = (
    sleep_present.astype(int)
    .groupby([sleep_summary_df["ID"], sleep_summary_df["streak_id"]])
    .cumsum()
)

# Replace any "0" with NAN
sleep_summary_df["Streak_Length"] = sleep_summary_df["Streak_Length"].replace(0, np.nan)

sleep_streak_length_df = pd.DataFrame()

#Calculate the maximum number of days for each streak, which would be the streak's
sleep_streak_length_df["max"] = sleep_summary_df["Streak_Length"].groupby([sleep_summary_df["ID"], sleep_summary_df["streak_id"]]).max()


overall_summary["Days_in_Row_Sleeping_Max"] = sleep_streak_length_df["max"].max()
overall_summary["Days_in_Row_Sleeping_Min"] = sleep_streak_length_df["max"].min()
overall_summary["Days_in_Row_Sleeping_Mean"] = sleep_streak_length_df["max"].mean()
overall_summary["Days_in_Row_Sleeping_Median"] = sleep_streak_length_df["max"].median()


overall_summary["Days_Missing_Sleep"] = sleep_summary_df["Asleep_Time"].isnull().sum()

overall_summary["Prop_Missing_Sleep"] = round(((sleep_summary_df["Asleep_Time"].isnull().sum())/len(sleep_summary_df)),2)


csv_name = "Sleep_Summary_"+RID+".csv"

sleep_summary_df.to_csv(os.path.join(PathKeeper.summarized_data_path,csv_name), index=False)

```

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false


prettify_info(HR_summary_df)

```

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false


new_presence_row=pd.DataFrame([{
    "ID": RID,
    "HR_Present": has_hr,
    "Sleep_Present": has_sleep,
    "Double_Support_Present": has_double_support,
    "Asymmetry_Present": has_asymmetry, 
    "Cognitive_Survey_Present": has_cognitive_survey,
    "Fatigue_Survey_Present": has_fatigue_survey,
    "Sleep_Survey_Present": has_sleep_survey
}])


presence_df = pd.concat([presence_df, new_presence_row], ignore_index=True)

presence_df.drop_duplicates(subset=["ID"], keep="last").to_csv(os.path.join(PathKeeper.data_log_path,"Data_Presence_Log.csv"), index=False)

overall_summary_df=pd.DataFrame([overall_summary])
csv_name = "Overall_Summary_"+RID+".csv"
overall_summary_df.to_csv(os.path.join(PathKeeper.summarized_data_path,csv_name), index=False)
```

# All Data Plot

## Faceted Plots

### Non Survey Only

```{python}

#| label: "Physio_Data_Plots"
#| eval: True
#| echo: false
#| warning: false
#| message: false

physio_fig  = make_subplots(rows=4, cols=1, subplot_titles=("HR", "Double Support", "Balance","Sleep Durations"))

for trace in hr_fig.data:
    physio_fig.add_trace(copy.deepcopy(trace), row=1, col=1)

for trace in double_support_fig.data:
    physio_fig.add_trace(copy.deepcopy(trace), row=2, col=1)

for trace in gait_fig.data:
    physio_fig.add_trace(copy.deepcopy(trace), row=3, col=1)

for trace in sleep_fig.data:
    physio_fig.add_trace(copy.deepcopy(trace), row=4, col=1)
    physio_fig.update_yaxes(range=[0,None], row=4, col=1)




physio_fig.update_xaxes(matches="x")
physio_fig.update_xaxes(visible=False, rangeslider_visible=False)
physio_fig.update_xaxes(visible=True, rangeslider_visible=True, row=4, col=1)
physio_fig.update_layout(showlegend=False)
physio_fig.show()

# new_fig = go.Figure()

# new_fig.add_trace

```

### Survey Data

```{python}

#| label: "Survey_Data_Plots"
#| eval: True
#| echo: false
#| warning: false
#| message: false

survey_fig  = make_subplots(rows=10, cols=1, subplot_titles=("Cognitive01", "Cognitive02", "Pain", "Depression","Physical Fatigue","Brain Fatigue","Sleepiness", "Sleep01", "Sleep02", "Sleep03"))

for index, trace in enumerate(cog_fig.data, start=1):
    trace2 = copy.deepcopy(trace)
    trace2.xaxis = None
    trace2.yaxis = None
    survey_fig.add_trace(trace2, row=index, col=1)

for index, trace in enumerate(fatigue_fig.data, start=5):
    trace2 = copy.deepcopy(trace)
    trace2.xaxis = None
    trace2.yaxis = None
    survey_fig.add_trace(trace2, row=index, col=1)

for index, trace in enumerate(sleepy_fig.data, start=8):
    trace2 = copy.deepcopy(trace)
    trace2.xaxis = None
    trace2.yaxis = None
    survey_fig.add_trace(trace2, row=index, col=1)

survey_fig.update_xaxes(matches="x")
survey_fig.update_xaxes(visible=False, rangeslider_visible=False)
survey_fig.update_xaxes(visible=True, rangeslider_visible=True, row=10, col=1)
survey_fig.update_layout(showlegend=False)
survey_fig.show()

# new_fig = go.Figure()

# new_fig.add_trace

```

### All Data

```{python}

#| label: "All_Data_Plots"
#| eval: True
#| echo: false
#| warning: false
#| message: false

total_fig  = make_subplots(rows=14, cols=1, subplot_titles=("HR", "Double Support", "Balance", "Sleep Durations","Cognitive01", "Cognitive02", "Pain", "Depression","Physical Fatigue","Brain Fatigue","Sleepiness", "Sleep01", "Sleep02", "Sleep03"))

for trace in hr_fig.data:
    total_fig.add_trace(copy.deepcopy(trace), row=1, col=1)

for trace in double_support_fig.data:
    total_fig.add_trace(copy.deepcopy(trace), row=2, col=1)

for trace in gait_fig.data:
    total_fig.add_trace(copy.deepcopy(trace), row=3, col=1)

for trace in sleep_fig.data:
    total_fig.add_trace(copy.deepcopy(trace), row=4, col=1)


for index, trace in enumerate(cog_fig.data, start=5):
    trace2 = copy.deepcopy(trace)
    trace2.xaxis = None
    trace2.yaxis = None
    total_fig.add_trace(trace2, row=index, col=1)

for index, trace in enumerate(fatigue_fig.data, start=9):
    trace2 = copy.deepcopy(trace)
    trace2.xaxis = None
    trace2.yaxis = None
    total_fig.add_trace(trace2, row=index, col=1)

for index, trace in enumerate(sleepy_fig.data, start=12):
    trace2 = copy.deepcopy(trace)
    trace2.xaxis = None
    trace2.yaxis = None
    total_fig.add_trace(trace2, row=index, col=1)

total_fig.update_xaxes(matches="x")
total_fig.update_xaxes(visible=False, rangeslider_visible=False)
total_fig.update_xaxes(visible=True, rangeslider_visible=True, row=14, col=1)
total_fig.update_layout(showlegend=False)
total_fig.show()

# new_fig = go.Figure()

# new_fig.add_trace

```

## Shared Plot

```{python}

all_traces = []

for trace in hr_fig.data:
    new_trace = copy.deepcopy(trace)
    new_trace.name="Average HR (BPM) from Last recording"
    all_traces.append(new_trace)

for trace in double_support_fig.data:
    new_trace = copy.deepcopy(trace)
    new_trace.name="Double Support Percentage"
    all_traces.append(new_trace)

for trace in gait_fig.data:
    new_trace = copy.deepcopy(trace)
    new_trace.name="Gait Balance"
    all_traces.append(new_trace)

for trace in sleep_fig.data:
    new_trace = copy.deepcopy(trace)
    all_traces.append(new_trace)

for index, trace in enumerate(cog_fig.data, start=5):
    new_trace = copy.deepcopy(trace)
    new_trace.xaxis = None
    new_trace.yaxis = None
    all_traces.append(new_trace)

for index, trace in enumerate(fatigue_fig.data, start=9):
    new_trace = copy.deepcopy(trace)
    new_trace.xaxis = None
    new_trace.yaxis = None
    all_traces.append(new_trace)

for index, trace in enumerate(sleepy_fig.data, start=12):
    new_trace = copy.deepcopy(trace)
    new_trace.xaxis = None
    new_trace.yaxis = None
    all_traces.append(new_trace)

fig = go.Figure(data=all_traces)

fig.update_xaxes(rangeslider_visible=True)

fig.update_layout(title="Shared Plot")
fig.show()
```

### Notices and Metainfo {.unnumbered .unlisted}

#### Copyright {.unnumbered .unlisted}

<details>

<notice>

Copyright © 2025 The Regents of the University of Michigan

This file is part of Yawnalyzer.

This program is free software: you can redistribute it and/or modify

it under the terms of the GNU General Public License as published by

the Free Software Foundation, either version 3 of the License, or (at your option) any later version.

This program is distributed in the hope that it will be useful,

but WITHOUT ANY WARRANTY; without even the implied warranty of

MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the

GNU General Public License for more details.

You should have received a copy of the GNU General Public License along

with this program. If not, see <https://www.gnu.org/licenses/>. </notice>

</details>

#### Session Info {.unnumbered .unlisted}

```{python}

#| label: Session_Information
#| echo: false
#| warning: false
#| message: false

session_info.show()

```