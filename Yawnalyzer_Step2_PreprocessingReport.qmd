---
title: "Yawnalyzer"
subtitle: "Preprocessing Report"
date: last-modified
date-format: "[Last Modified:] DD MMM YYYY"
license: "GPL-3.0-or-later"
copyright:
    holder: "The Regents of the University of Michigan"
    year: 2025
rights: |
    © 2025 The Regents of the University of Michigan.
    
    This file is part of Yawnalyzer.
    
    Yawnalyzer is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.
format:
    html:
        toc: true
        toc-depth: 3
        code-fold: true
        df-print: paged
        embed-resources: true
        html-math-method: mathjax
jupyter: python3
---

```{python}

#| tags: [parameters]
#| echo: false
#| message:
#| code-fold: false

RID = "PARTICIPANT_ID"

```

```{python}

#| label: "Import_Packages" 
#| echo: false
#| message:
#| code-fold: false

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
#import neurokit2 as nk
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import datetime as dt
from datetime import datetime, timedelta
from IPython.display import Markdown, display
import session_info
import yasa
import copy
import PathKeeper

```

# About this Report

```{python}

#| label: ParticipantID
#| code-hide: true
#| echo: false



Markdown(f"> Participant: _**{RID}**_")

```

> Generation Date: `{python} dt.datetime.now().strftime("%Y-%m-%d")`

This is a processing report for Subject ID (SID) **`{python} RID`** from the MS-EMA project (IRB #HUM00265263; PI: Tiffany Braley, MD). MS-EMA is an Apple watch-based sleep tracking study conducted with patients with Multiple Sclerosis.

This report provides both a sense of quality and summary metrics for the following types of information:

-   Heart rate (derived from PPG)
-   Sleep-related metrics
-   Gait and balance

Data for the above were collected over the span of approximately 12 weeks for each subject. Plots contained within this report are summarized by week.

```{python}

#| label: "Functions"
#| echo: false
#| warning: false
#| message: false

def prettify_info(df, memory_usage=False, deep=True, sort_by_nulls=False, show_unique=True, show_stats=True):
  n=len(df)
  info_df=pd.DataFrame({
    
    "Column":df.columns,
    "Total Count" : df.count(),
    "Not-Nulls Count" : df.notnull().sum(),
    "Missing Count" : df.isnull().sum(),
    "Type" : df.dtypes.astype(str)
    })
  if show_unique:
    info_df["Unique Count"] = df.nunique(dropna=True)
  
  if show_stats:
    numeric_cols = df.select_dtypes(include=[np.number])

    sum_stats_dictionary ={
        "Means" : numeric_cols.mean(),#.round(5)
        "Median" : numeric_cols.median(),#.round(5)
        "Standard Deviation" : numeric_cols.std(),#.round(5)
        "Min": numeric_cols.min(),
        "25%": numeric_cols.quantile(0.25),
        "75%": numeric_cols.quantile(0.75),
        "Max": numeric_cols.max()
    }

    for stat_name, stat_values in sum_stats_dictionary.items():
        valid_numeric_cols = set(stat_values.index)

        info_df[stat_name] = info_df["Column"].apply(
            lambda col: stat_values[col] if col in valid_numeric_cols else " "
        )

  base_cols = ["Total Count","Not-Nulls Count","Missing Count"]
  uniqueness_cols = ["Unique Count"] if show_unique else []
  stat_cols = list(sum_stats_dictionary.keys()) if show_stats else []
  info_df = info_df[base_cols + uniqueness_cols + stat_cols + ["Type"]]

  if memory_usage:
    mem = df.memory_usage(deep=deep).sum / 1024**2
    print(f"Memory usage: {mem.df} MB")

  
  return info_df

def add_fig_traces(fig_collection, source_fig, start_row,end_row, col=1, reset_axes=True, empty_label="No data",yaxis_range=None):

    n_rows = end_row - start_row + 1
    source_traces = (
        list(source_fig.data)
        if (source_fig is not None and hasattr(source_fig, "data"))
        else []
    )
    
    for i in range(n_rows):
        row = start_row + i

        if i < len(source_traces):
            trace2 = copy.deepcopy(source_traces[i])
            if reset_axes:
                trace2.xaxis = None
                trace2.yaxis = None
            fig_collection.add_trace(trace2, row=row, col=col)
        else:
            # Placeholder trace 
            fig_collection.add_trace(
                go.Scatter(
                    x=[],
                    y=[],
                    mode="lines",
                    showlegend=False,
                    hoverinfo="skip",
                ),
                row=row,
                col=col,
            )

            # Add "No data" label within this subplot
            fig_collection.add_annotation(
                text=empty_label,
                x=0.5,
                y=0.5,
                xref="x domain",
                yref="y domain",
                showarrow=False,
                font=dict(color="gray"),
                row=row,
                col=col,
            )
            

def add_traces_single_plot(source_fig, *, name_override=None, reset_axes=False):
    if source_fig is None or not hasattr(source_fig, "data") or len(source_fig.data) == 0:
        return []
    
    traces = []
    for trace in source_fig.data:
        copied_trace = copy.deepcopy(trace)

        copied_trace.xaxis="x"
        copied_trace.yaxis = "y"
        
        if name_override is not None:
            copied_trace.name=name_override
        
        traces.append(copied_trace)
    return traces

def to_standarized_timezone(time_col, time_zone) :
    #Convert time column to datetime
    time_col = pd.to_datetime(time_col, errors="coerce")
    #If there is no Timezone set, set timezone
    if getattr(time_col.dt, "tz", None) is None:
        return time_col.dt.tz_localize(time_zone)
    # Convert the datetime to the desired timezone.
    return time_col.dt.tz_convert(time_zone)


```

```{python}

#| label: "Inital-Read"
#| echo: false
#| warning: false
#| message: false

presence_df = pd.read_csv(os.path.join(PathKeeper.data_log_path,"Data_Presence_Log.csv"))

hr_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path,"hr_collapsed.csv"), index_col=["index_1"], dtype={
  "ID": "string",
  "submission_date": "string",
  "file_type": "string",
  "HR": "float64",
  "Timestamp":  "float64",
  "filename": "string" 
 }
)

sleep_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path,"sleep_collapsed.csv"), index_col=["index_1"])

gait_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path,"gait_collapsed.csv"), index_col=["index_1"])

double_support_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path,"double_support_collapsed.csv"), index_col=["index_1"])

asymmetry_df =pd.read_csv(os.path.join(PathKeeper.merged_data_path,"asymmetry_collapsed.csv"), index_col=["index_1"])

fatigue_survey_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path, "fatigue_survey_collapsed.csv"), index_col=["index_1"]
)

cognitive_survey_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path, "cog_collapsed.csv"), index_col=["index_1"]
)

sleep_survey_df = pd.read_csv(os.path.join(PathKeeper.merged_data_path, "sleep_survey_collapsed.csv"), index_col=["index_1"]
)

hr_df = hr_df[hr_df["ID"] == RID].copy()
sleep_df = sleep_df[sleep_df["ID"] == RID].copy()
gait_df = gait_df[gait_df["ID"] == RID].copy()
double_support_df = double_support_df[double_support_df["ID"] == RID].copy()
asymmetry_df = asymmetry_df[asymmetry_df["ID"] == RID].copy()
sleep_survey_df = sleep_survey_df[sleep_survey_df["ID"] == RID].copy()
cognitive_survey_df = cognitive_survey_df[cognitive_survey_df["ID"] == RID].copy()
fatigue_survey_df = fatigue_survey_df[fatigue_survey_df["ID"] == RID].copy()

all_surveys_df = sleep_survey_df.drop("Question4", axis=1).merge(cognitive_survey_df, how="outer")

all_surveys_df = all_surveys_df.merge(fatigue_survey_df.drop("Question4", axis=1), how="outer")

all_surveys_df["Sleep03"] = all_surveys_df["Sleep03"].str.strip().replace("Sleep03: No new symptoms","Sleep03: 0 = No new symptoms")

if "all_surveys_df" in locals() and len(all_surveys_df) >0:
    all_surveys_df[["survey_date", "survey_type"]] = all_surveys_df["Survey"].str.rsplit("_", n=1, expand=True)

cols = ['Sleep01', 'Sleep02', 'Sleep03', 'Cognitive01','Cognitive02', "Pain",'Depression', 'Physical_Fatigue', 'Brain_Fatigue', 'Sleepiness']


for c in cols:
    col_as_series = all_surveys_df[c].fillna("").astype(str)
    non_missing_index = col_as_series.str.contains(":")
    non_missing_series = col_as_series.str.split(":", n=1, expand=True)
    non_missing_df = non_missing_series.reindex(columns=[0,1])
    non_missing_df = non_missing_df.apply(lambda col: col.str.strip())

    all_surveys_df[f"{c}_question"] = np.where(
        non_missing_index,
        non_missing_df[0],
        f"{c}_question"
    )  

    all_surveys_df[f"{c}_value"] = np.where(
        non_missing_index,
        non_missing_df[1],
        np.nan
    )
    
    all_surveys_df[f"{c}_value"] = ( all_surveys_df[f"{c}_value"].astype(str).str.extract(r"(\d+)").astype("Int64"))

all_surveys_df = all_surveys_df.drop(['Sleep01', 'Sleep02', 'Sleep03', 'Cognitive01','Cognitive02','Pain','Depression', 'Physical_Fatigue', 'Brain_Fatigue', 'Sleepiness'], axis=1)

cols_to_drop = [col for col in all_surveys_df.columns if "_question" in col]

all_surveys_df = all_surveys_df.drop(columns=cols_to_drop)
all_surveys_df.columns = all_surveys_df.columns.str.replace("_value","")

if "all_surveys_df" in locals() and len(all_surveys_df) >0:
    cognitive_survey_df = all_surveys_df[all_surveys_df["survey_type"] == "Cognitive"].dropna(axis=1, how="all").drop(columns=["survey_type"])

    fatigue_survey_df = all_surveys_df[all_surveys_df["survey_type"] == "Fatigue"].dropna(axis=1, how="all").drop(columns=["survey_type"])

    sleep_survey_df  = all_surveys_df[all_surveys_df["survey_type"] == "Sleep"].dropna(axis=1, how="all").drop(columns=["survey_type"])

has_hr ="hr_df" in locals() and len(hr_df) > 0

has_sleep ="sleep_df" in locals() and len(sleep_df) > 0

has_gait ="gait_df" in locals() and len(gait_df) > 0

has_double_support ="double_support_df" in locals() and len(double_support_df) > 0

has_asymmetry= "asymmetry_df" in locals() and len(asymmetry_df) > 0

has_cognitive_survey= "cognitive_survey_df" in locals() and len(cognitive_survey_df) > 0
has_fatigue_survey= "fatigue_survey_df" in locals() and len(fatigue_survey_df) > 0
has_sleep_survey= "sleep_survey_df" in locals() and len(sleep_survey_df) > 0

overall_summary = {}

overall_summary["ID"] =  RID;

del non_missing_df, non_missing_index, non_missing_series, col_as_series, cols, cols_to_drop, c
```

```{python}

#| label: "Time-Conversions"
#| eval: True
#| echo: false
#| warning: false
#| message: false

#Sleep 

sleep_df["StartISO"] = pd.to_datetime(sleep_df["StartISO"], utc=True).dt.tz_convert(
    "America/Detroit"
)

sleep_df["EndISO"] = pd.to_datetime(sleep_df["EndISO"], utc=True).dt.tz_convert(
    "America/Detroit"
)

sleep_df["StartISO"] = (
    sleep_df["StartISO"]
    .infer_objects()
    .fillna(pd.to_datetime(sleep_df["Start"], unit="s", utc=True))
)

sleep_df["EndISO"] = (
    sleep_df["EndISO"]
    .infer_objects()
    .fillna(pd.to_datetime(sleep_df["End"], unit="s", utc=True))
)

sleep_df = sleep_df.sort_values(by="StartISO")

sleep_df["gap_seconds"]  = (
    sleep_df.groupby("ID")["EndISO"].shift().rsub(sleep_df["StartISO"]).dt.total_seconds()
    )
sleep_df["gap_hours"] = (sleep_df["gap_seconds"]/3600) 

sleep_df["Session"] = sleep_df["gap_hours"].isna() | (sleep_df["gap_hours"] >=2)

sleep_df["session_id"] = sleep_df["Session"].cumsum()

sleep_df = (
    sleep_df.groupby(["session_id",'ID', 'submission_date', 'file_type', 'filename']).agg(
        ID = ("ID", "first"),
        submission_date = ('submission_date', "first"), 
        file_type = ('file_type',"first"),
        filename=('filename', 'first'),
        StartISO =('StartISO', "min"),
        EndISO = ('EndISO', "max"),
        Start = ('Start', "min"),
        End = ('End', "max")
    )
    .reset_index(drop=True)
)

sleep_df["Duration"] = sleep_df["EndISO"] - sleep_df["StartISO"]
sleep_df["Duration_in_Minutes"] = sleep_df["Duration"].dt.total_seconds()/60

sleep_df["hour"] = sleep_df["EndISO"].dt.hour

sleep_df["Before_or_After_noon"] = np.where(sleep_df["EndISO"].dt.hour < 12,"Morning","Afternoon")

sleep_df["Night_of_Sleep"] = np.where(
    sleep_df["Before_or_After_noon"] == "Morning",
    (sleep_df["EndISO"] - pd.Timedelta(days=1)).dt.date,
    sleep_df["EndISO"].dt.date,
)

sleep_df["KeepOrDrop"] = np.where(
    sleep_df["Duration_in_Minutes"] <= (24*60), 1,0#24 hours of 60 minutes
)

#sleep_df = sleep_df.dropna(subset=["Duration_in_Minutes"])

sleep_df["Night_of_Sleep"] = pd.to_datetime(
    sleep_df["Night_of_Sleep"], utc=True,
    errors="coerce").dt.tz_convert("America/Detroit").dt.date


sleep_df["EndISO"] = (
    sleep_df["EndISO"]
    .infer_objects()
    .fillna(pd.to_datetime(sleep_df["End"], unit="s", utc=True))
)

sleep_df=sleep_df.drop(["hour","Before_or_After_noon","Duration"], axis=1)

has_sleep ="sleep_df" in locals() and len(sleep_df) > 0

#Heart Rate

hr_df["TimestampISO"] = pd.to_datetime(hr_df["TimestampISO"],errors="coerce", utc=True)


hr_df["TimestampISO"] = (
    hr_df["TimestampISO"]
    .infer_objects()
    .fillna(pd.to_datetime(hr_df["Timestamp"], unit="s", utc=True))
)

hr_df["TimestampISO"] = (
    pd.to_datetime(hr_df["TimestampISO"], utc=True, errors="coerce")
    .dt.tz_convert("America/Detroit")
    .infer_objects()
)   

# Gait
gait_df["TimestampISO"] = pd.to_datetime(gait_df["TimestampISO"], utc=False)

gait_df["TimestampISO"] = (
    gait_df["TimestampISO"]
    .infer_objects()
    .fillna(pd.to_datetime(gait_df["Timestamp"], unit="s", utc=True).dt.tz_convert("America/Detroit"))
)
# Double Support
double_support_df["TimestampISO"] = pd.to_datetime(double_support_df["TimestampISO"], utc=False)

double_support_df["TimestampISO"] = (
    double_support_df["TimestampISO"]
    .infer_objects()
    .fillna(pd.to_datetime(double_support_df["Timestamp"], unit="s", utc=True).dt.tz_convert("America/Detroit"))
)
# Asymmetry

asymmetry_df["TimestampISO"] = pd.to_datetime(asymmetry_df["TimestampISO"], utc=False)

asymmetry_df["TimestampISO"] = (
    asymmetry_df["TimestampISO"]
    .infer_objects()
    .fillna(pd.to_datetime(asymmetry_df["Timestamp"], unit="s", utc=True).dt.tz_convert("America/Detroit"))
)
# Cognitive survey

cognitive_survey_df["Timestamp"] = pd.to_datetime(cognitive_survey_df["Timestamp"],errors="coerce", utc=True).dt.tz_convert(
    "America/Detroit"
)

# Fatigue survey

fatigue_survey_df["Timestamp"] = pd.to_datetime(fatigue_survey_df["Timestamp"],errors="coerce", utc=True).dt.tz_convert(
    "America/Detroit"
)

# Sleep survey

sleep_survey_df["Timestamp"] = pd.to_datetime(sleep_survey_df["Timestamp"],errors="coerce", utc=True).dt.tz_convert(
    "America/Detroit"
)



```

```{python}
#|label: Sort dataframes by Time
#| echo: false
#| warning: false
#| message: false

hr_df=hr_df.sort_values(by="TimestampISO").copy()
sleep_df = sleep_df.sort_values(by="StartISO").copy()
gait_df = gait_df.sort_values(by="TimestampISO").copy()
double_support_df = double_support_df.sort_values("TimestampISO").copy()
asymmetry_df = asymmetry_df.sort_values("TimestampISO").copy()
cognitive_survey_df = cognitive_survey_df.sort_values("Timestamp").copy()
fatigue_survey_df = fatigue_survey_df.sort_values("Timestamp").copy()
sleep_survey_df = sleep_survey_df.sort_values("Timestamp").copy()

```

```{python}

#|label: Remove First Week of Data
#| echo: false
#| warning: false
#| message: false

hr_df["TimestampISO"] = to_standarized_timezone(hr_df["TimestampISO"], "America/Detroit")
sleep_df["StartISO"]  = to_standarized_timezone(sleep_df["StartISO"], "America/Detroit")
sleep_df["EndISO"]    = to_standarized_timezone(sleep_df["EndISO"], "America/Detroit")
gait_df["TimestampISO"] = to_standarized_timezone(gait_df["TimestampISO"], "America/Detroit")
double_support_df["TimestampISO"] = to_standarized_timezone(double_support_df["TimestampISO"], "America/Detroit")
asymmetry_df["TimestampISO"] = to_standarized_timezone(asymmetry_df["TimestampISO"], "America/Detroit")
cognitive_survey_df["Timestamp"] = to_standarized_timezone(cognitive_survey_df["Timestamp"], "America/Detroit")
fatigue_survey_df["Timestamp"]   = to_standarized_timezone(fatigue_survey_df["Timestamp"], "America/Detroit")
sleep_survey_df["Timestamp"]     = to_standarized_timezone(sleep_survey_df["Timestamp"], "America/Detroit")


first_timestamps = [
    hr_df["TimestampISO"].min(),
    sleep_df.loc[sleep_df["KeepOrDrop"] == 1, "StartISO"].min(),
    gait_df["TimestampISO"].min(),
    double_support_df["TimestampISO"].min(),
    asymmetry_df["TimestampISO"].min(),
    cognitive_survey_df["Timestamp"].min(),
    fatigue_survey_df["Timestamp"].min(),
    sleep_survey_df["Timestamp"].min()
]

first_timestamps = [
    #Double confirm conversion to desired Timezone ("Detroit")
    timestamp.tz_convert("America/Detroit") if timestamp.tzinfo is not None else timestamp.tz_localize("America/Detroit")
    for timestamp in first_timestamps
    if pd.notna(timestamp)
]


last_timestamps = [
    hr_df["TimestampISO"].max(),
    sleep_df.loc[sleep_df["KeepOrDrop"] == 1,"EndISO"].max(),
    gait_df["TimestampISO"].max(),
    double_support_df["TimestampISO"].max(),
    asymmetry_df["TimestampISO"].max(),
    cognitive_survey_df["Timestamp"].max(),
    fatigue_survey_df["Timestamp"].max(),
    sleep_survey_df["Timestamp"].max()
]

last_timestamps = [
    #Double confirm conversion to desired Timezone ("Detroit")
    timestamp.tz_convert("America/Detroit") if timestamp.tzinfo is not None else timestamp.tz_localize("America/Detroit")
    for timestamp in last_timestamps
    if pd.notna(timestamp)
]

start = min(first_timestamps) + pd.Timedelta(days=7) # Determine 7 days after the earliest recorded piece of data present.
end   = max(last_timestamps) - pd.Timedelta(days=1) # Determine 1 day before the last recorded piece of data present

# HR 
hr_df = hr_df.loc[
    (hr_df["TimestampISO"] >= start) & (hr_df["TimestampISO"] <= end) 
].copy()

# Sleep 
sleep_df = sleep_df.loc[
    (sleep_df["StartISO"] >= start) & (sleep_df["EndISO"] <= end) 
].copy()

# Gait 
gait_df = gait_df.loc[
    (gait_df["TimestampISO"] >= start) & (gait_df["TimestampISO"] <= end) 
].copy()

# Double Support 
double_support_df = double_support_df.loc[
    (double_support_df["TimestampISO"] >= start) & (double_support_df["TimestampISO"] <= end) 
].copy()



# Asymmetry 
asymmetry_df = asymmetry_df.loc[
    (asymmetry_df["TimestampISO"] >= start) & (asymmetry_df["TimestampISO"] <= end) 
].copy()

# Cognitive Survey 
cognitive_survey_df = cognitive_survey_df.loc[
    (cognitive_survey_df["Timestamp"] >= start) & (cognitive_survey_df["Timestamp"] <= end) 
].copy()

# Fatigue Survey 
fatigue_survey_df = fatigue_survey_df.loc[
    (fatigue_survey_df["Timestamp"] >= start) & (fatigue_survey_df["Timestamp"] <= end) 
].copy()

# Sleep Survey 
sleep_survey_df = sleep_survey_df.loc[
    (sleep_survey_df["Timestamp"] >= start) & (sleep_survey_df["Timestamp"] <= end) 
].copy()

```
# Heart Rate

## General Information

```{python}

#| label: Prettify_HR_Table
#| echo: false
#| warning: false
#| message: false

if has_hr:
    display(prettify_info(hr_df))
else:
    display(Markdown(f"_**No Heart Rate Data Exists**_"))

```

## Plotting

```{python}

#| label: HR_Plot
#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_hr:
    hr_sorted_df = hr_df.sort_values(by="TimestampISO")
    hr_sorted_df["Time_Averaged_Over"] = hr_sorted_df.sort_values(["ID","TimestampISO"]).groupby("ID")["TimestampISO"].diff()
    hr_sorted_df["Time_Averaged_Over_in_Minutes"] =  hr_sorted_df["Time_Averaged_Over"].dt.total_seconds()/60

    hr_fig = go.Figure()

    hr_fig.add_trace(
    go.Scatter(
        x=hr_sorted_df["TimestampISO"],
        y=hr_sorted_df["HR"],
        mode="lines+markers",
        marker=dict(
        color="red"
        ),
        line=dict(
        color="green",
        width=1
        )
    )
    )

    # fig = px.line(
    #   x=q["TimestampISO"],
    #   y=q["HR"],
    #   markers=True
    #   )
    # fig.update_traces(
    #   line_color="red",
    # )
    hr_fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )
    hr_fig.show()
else:
    display(Markdown(f"_**No Heart Rate Data Exists**_"))

```

### Time Mean HR calculated Over

```{python}
if has_hr:
    hr_gap_df = hr_sorted_df.sort_values("Time_Averaged_Over_in_Minutes")
    
    csv_name = "Gaps_HR_"+RID+".csv"

    hr_sorted_df.to_csv(os.path.join(PathKeeper.summarized_data_path,csv_name), index=False)

    #hr_histogram_df = hr_histogram_df.tips()

    hr_box_fig =px.box(hr_gap_df, y="Time_Averaged_Over_in_Minutes", x="ID",  title="Distribution of Distances between HR recordings in Minutes")

    hr_box_fig.show()

    hr_hist_fig = px.histogram(hr_gap_df, x="Time_Averaged_Over_in_Minutes", title="Histogram of Time Difference between HR recordings in Minutes")

    hr_hist_fig.show()
else:
    display(Markdown(f"_**No Heart Rate Data Exists**_"))
```

# Sleeping

## General Information

```{python}
#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_sleep:
    display(prettify_info(sleep_df))
else:
    display(Markdown(f"_**No Sleep Data Exists**_"))
    # with open("MissingSleep.txt", "r") as file:
    # content = file.read()
    # print(content)

```

## Plotting

Below is a stacked bargraph. Each bar on the x-axis represents a different potential night of sleep that occurred between the start and end of their participation. If they had multiple sleep sessison for a given night of sleep, each session is a different color, and are stacked.

The y-axis ths the duration of the recorded sleep session in minutes.

The blue line represents 8 hours of sleep.

```{python}

#| label: Sleep_Duration_Plot
#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_sleep:
    sleep_temp_df = sleep_df[sleep_df["KeepOrDrop"] == 1].sort_values(by="Night_of_Sleep")
    sleep_temp_df['Sleep Session'] = sleep_temp_df.groupby('Night_of_Sleep').cumcount()
    sleep_temp_df = sleep_temp_df.dropna(subset=["Sleep Session"])
    sleep_temp_df["Sleep Session"] = "Sleep Session: " + (sleep_temp_df["Sleep Session"]+1).astype(str) 

    sleep_fig = go.Figure()
    sleep_fig.add_hline(y=(60*8), line_dash="dash", line_color="cyan", layer='below')

    for session in sleep_temp_df["Sleep Session"].dropna().unique():
        filtered_df = sleep_temp_df[sleep_temp_df["Sleep Session"] == session]

        sleep_fig.add_trace(
            go.Bar(
                x=filtered_df["Night_of_Sleep"],
                y=filtered_df["Duration_in_Minutes"],
                name=session     # ← now a proper string label
            )
        )
    sleep_fig.update_layout(
        xaxis_title = "Night of Sleep",
        yaxis_title = "Duration of Sleep (in Minutes)",
        barmode="stack",
        showlegend=False
    )

    sleep_fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )
    sleep_fig.show()
else:
    display(Markdown(f"_**No Sleep Data Exists**_"))


```

## Hypnograph-like plot

```{python}
#| warning: false
#| message: false

if has_sleep:
    night = pd.to_datetime(sleep_df["Night_of_Sleep"], errors="coerce").dt.tz_localize("America/Detroit")

    night = night.dt.normalize()

    earliest_day = night.min()
    latest_day = night.max()

    latest_time = max(sleep_df["EndISO"])

    earliest_time = min(sleep_df["StartISO"])-pd.Timedelta(2, unit="h")

    sleep_days_df = pd.DataFrame({
        "GlobalDay": pd.date_range(
            start=earliest_day,
            end=latest_day,
            freq="1D"
        )
    }
    )


    time_df = pd.DataFrame(
        {
            "GlobalTime": pd.date_range(start=earliest_time, end=latest_time, freq="30s"),
            "Asleep": "0",
        }
    )

    session_interval = pd.IntervalIndex.from_arrays(sleep_df["StartISO"], sleep_df["EndISO"], closed="both")

    has_sleep_interval_including_drops = session_interval.get_indexer_for(time_df["GlobalTime"])
    group = np.where(has_sleep_interval_including_drops == -1, np.nan, sleep_df["KeepOrDrop"].to_numpy()[has_sleep_interval_including_drops])

    time_df["Hypno"] = np.select(
        [has_sleep_interval_including_drops == -1, # Is not inside *ANY* interval
        group == 1], 
        [
            "WAKE",
            "SLEEP"
        ],
        default="UNS"

    )

    hypno_order =["SLEEP", "WAKE", "UNS"]
    hypno_color_map = {
        "SLEEP": "red",
        "WAKE": "black",
        "UNS": "black"
    }

    hypno_number_map = {
        "SLEEP": 0,
        "WAKE": 1,
        "UNS": 2
    }

    time_sorted_df = time_df.sort_values(by="GlobalTime")
    hypno_colors = time_sorted_df["Hypno"].map(hypno_color_map).fillna("black")
    time_sorted_df["DummyHypno"] = time_sorted_df["Hypno"].map(hypno_number_map)


    time_fig = go.Figure()

    time_fig.add_trace(
    go.Scatter(
        x=time_sorted_df["GlobalTime"],
        y=time_sorted_df["Hypno"],
        mode="lines+markers",
        marker=dict(
        color=hypno_colors
        ),
        line=dict(
        color="black",
        width=1
        )
    )
    )

    time_fig.update_layout(
        yaxis=dict(categoryorder="array", categoryarray=hypno_order),
        template="plotly_white"
    )
    time_fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )

    time_fig.show()

    # hypno=yasa.Hypnogram(time_sorted_df["Hypno"], n_stages=2, freq="30s")

    # hypno.plot_hypnogram()
    time_fig_for_group = go.Figure()

    time_fig_for_group.add_trace(
    go.Scatter(
        x=time_sorted_df["GlobalTime"],
        y=time_sorted_df["DummyHypno"],
        mode="lines+markers",
        marker=dict(
        color=hypno_colors
        ),
        line=dict(
        color="black",
        width=1
        )
    )
    )

    time_fig_for_group.update_layout(
        yaxis=dict(categoryorder="array", categoryarray=hypno_order, tickmode="array", tickvals=[0,1,2], ticktext=hypno_order),
        template="plotly_white"
    )
    time_fig_for_group.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )


else:
    display(Markdown(f"_**No Sleep Data Exists**_"))


```


## Number of Consecutive 

# Gait and Walking Metrics



## Gait

### General Information

```{python}
#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_gait:
    display(prettify_info(gait_df))
else:
    display(Markdown(f"_**No Gait Data Exists**_"))

```

### Plot

```{python}
#| eval: true
#| echo: false
#| warning: false
#| message: false


if has_gait:
    gait_df["TimestampISO"] = (
    pd.to_datetime(gait_df["TimestampISO"], utc=True, errors="coerce")
    .dt.tz_convert("America/Detroit")
    .infer_objects()
)   

    gait_sorted_df = gait_df.sort_values(by="TimestampISO")

    gait_sorted_df["Balance"] = gait_sorted_df["Balance"]*100 

    gait_fig = go.Figure()

    gait_fig.add_trace(
    go.Scatter(
        x=gait_sorted_df["TimestampISO"],
        y=gait_sorted_df["Balance"],
        mode="lines+markers",
        marker=dict(
        color="orange"
        ),
        line=dict(
        color="green",
        width=1
        )
    )
    )

    # fig = px.line(
    #   x=q["TimestampISO"],
    #   y=q["HR"],
    #   markers=True
    #   )
    # fig.update_traces(
    #   line_color="red",
    # )
    gait_fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )
    gait_fig.add_hline(y=50, line_dash="dash", line_color="green", annotation_text="Balanced Gait")
    gait_fig.show()
else:
    gait_sorted_df = gait_df.sort_values(by="TimestampISO")
    gait_sorted_df["TimestampISO"] = pd.to_datetime(gait_sorted_df["TimestampISO"], errors="coerce").dt.tz_convert("America/Detroit")
    display(Markdown(f"_**No Gait Data Exists**_"))
```

## Double Support

### General Information

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_double_support:
    display(prettify_info(double_support_df))
else:
    display(Markdown(f"_**No Double Support Data Exists**_"))

```

### Plot

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_double_support:
    double_support_sorted_df = double_support_df.sort_values(by="TimestampISO")
    IsoTime = pd.to_datetime(double_support_sorted_df["TimestampISO"], errors="coerce", utc=True)

    double_support_sorted_df["TimestampISO"] = IsoTime.dt.tz_convert("America/Detroit")
    double_support_sorted_df["Percentage"] = double_support_sorted_df["Percentage"]*100 

    double_support_fig = go.Figure()

    double_support_fig.add_trace(
    go.Scatter(
        x=double_support_sorted_df["TimestampISO"],
        y=double_support_sorted_df["Percentage"],
        mode="lines+markers",
        marker=dict(
        color="blue"
        ),
        line=dict(
        color="green",
        width=1
        )
    )
    )

    double_support_fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=1, label="1 day", step="day", stepmode="backward"),
                dict(count=3, label="3 days", step="day", stepmode="backward"),
                dict(count=5, label="5 day", step="day", stepmode="backward"),
                dict(count=7, label="1 week", step="day", stepmode="backward"),
                dict(step="all")
            ])
        )
    )
    double_support_fig.show()

else:
    double_support_sorted_df = double_support_df.sort_values(by="TimestampISO")
    double_support_sorted_df["TimestampISO"] = pd.to_datetime(double_support_sorted_df["TimestampISO"], errors="coerce").dt.tz_localize("America/Detroit")

    display(Markdown(f"_**No Double Support Data Exists**_"))
```

# Surveys

## Cognitive

### General Information

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_cognitive_survey:
    display(prettify_info(cognitive_survey_df))
else:
    display(Markdown(f"_**No Cognitive Survey Responses Exists**_"))

```

### Plotting

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false
if has_cognitive_survey:
    cognitive_survey_long_df = cognitive_survey_df.melt(id_vars=["ID","survey_date", "Timestamp"], value_vars=["Cognitive01","Cognitive02","Pain", "Depression"], var_name='Questions', value_name='Value')

    cognitive_survey_long_df["survey_date"] = (
        pd.to_datetime(cognitive_survey_long_df["survey_date"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/Detroit")
    )

####


    cognitive_survey_long_df = cognitive_survey_long_df.sort_values(["survey_date", "Timestamp"])
    
    cog_fig = px.line(
        cognitive_survey_long_df,
        x="survey_date",
        y="Value",
        color="Questions",
        facet_row="Questions",
        markers=True
    )
    cog_fig.for_each_annotation(
    lambda a: a.update(text=a.text.split("=")[-1])
    
    )

    # 1. Match all x-axes
    cog_fig.update_xaxes(matches="x")

    # 2. Disable sliders everywhere
    cog_fig.update_xaxes(rangeslider_visible=False)

    # 3. Enable slider ONLY on the bottom x-axis
    bottom_xaxis = min(
        cog_fig.select_xaxes(),
        key=lambda ax: ax.domain[0]
    )
    bottom_xaxis.rangeslider.visible = True
    cog_fig.update_layout(showlegend=False)


    cog_fig.show()
else:
    cognitive_survey_long_df = pd.DataFrame(columns=["ID","survey_date","Timestamp","Questions","Value"])
    cognitive_survey_long_df["survey_date"] = (
        pd.to_datetime(cognitive_survey_long_df["survey_date"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/Detroit")
    )
    cognitive_survey_long_df["Timestamp"] = (
        pd.to_datetime(cognitive_survey_long_df["Timestamp"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/Detroit")
    )
    display(Markdown(f"_**No Cognitvie Survey Data Exists**_"))
```

## Fatigue

### General Information

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_fatigue_survey:
    display(prettify_info(fatigue_survey_df))
else:
    display(Markdown(f"_**No Fatigue Survey Responses Exists**_"))

```

### Plotting

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false
if has_fatigue_survey:
    fatigue_survey_long_df = fatigue_survey_df.melt(id_vars=["ID","survey_date", "Timestamp"], value_vars=[ 'Physical_Fatigue', 'Brain_Fatigue', 'Sleepiness'], var_name='Questions', value_name='Value')

    fatigue_survey_long_df["survey_date"] = (
        pd.to_datetime(fatigue_survey_long_df["survey_date"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/Detroit")
    )

####


    fatigue_survey_long_df=fatigue_survey_long_df.sort_values(["survey_date", "Timestamp"])
    fatigue_fig = px.line(
        fatigue_survey_long_df,
        x="survey_date",
        y="Value",
        color="Questions",
        facet_row="Questions",
        markers=True,
    )
    fatigue_fig.for_each_annotation(
    lambda a: a.update(text=a.text.split("=")[-1])
    
    )
    
    fatigue_fig.update_xaxes(matches="x")

    # 2. Disable sliders everywhere
    fatigue_fig.update_xaxes(rangeslider_visible=False)

    # 3. Enable slider ONLY on the bottom x-axis
    bottom_xaxis = min(
        fatigue_fig.select_xaxes(),
        key=lambda ax: ax.domain[0]
    )
    fatigue_fig.update_layout(showlegend=False)

    bottom_xaxis.rangeslider.visible = True


    fatigue_fig.show()
else:
    fatigue_survey_long_df = pd.DataFrame(columns=["ID","survey_date","Timestamp","Questions","Value"])
    fatigue_survey_long_df["survey_date"] = (
        pd.to_datetime(fatigue_survey_long_df["survey_date"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/Detroit")
    )
    fatigue_survey_long_df["Timestamp"] = (
        pd.to_datetime(fatigue_survey_long_df["Timestamp"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/Detroit")
    )
    display(Markdown(f"_**No Fatigue Survey Data Exists**_"))
```

## Sleepiness

### General Information

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

if has_sleep_survey:
    display(prettify_info(fatigue_survey_df))
else:
    display(Markdown(f"_**No Sleep Survey Responses Exists**_"))

```

### Plotting

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false
if has_sleep_survey:
    sleep_survey_long_df = sleep_survey_df.melt(id_vars=["ID","survey_date", "Timestamp"], value_vars=[ 'Sleep01', 'Sleep02', 'Sleep03'], var_name='Questions', value_name='Value')

    sleep_survey_long_df["survey_date"] = (
        pd.to_datetime(sleep_survey_long_df["survey_date"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/Detroit")
    )


####
    sleep_survey_long_df=sleep_survey_long_df.sort_values(["survey_date", "Timestamp"])
    sleepy_fig = px.line(
        sleep_survey_long_df,
        x="survey_date",
        y="Value",
        color="Questions",
        facet_row="Questions",
        markers=True,
    )
    sleepy_fig.for_each_annotation(
    lambda a: a.update(text=a.text.split("=")[-1])
    
    )
    
    sleepy_fig.update_xaxes(matches="x")

    # 2. Disable sliders everywhere
    sleepy_fig.update_xaxes(rangeslider_visible=False)

    # 3. Enable slider ONLY on the bottom x-axis
    bottom_xaxis = min(
        sleepy_fig.select_xaxes(),
        key=lambda ax: ax.domain[0]
    )
    sleepy_fig.update_layout(showlegend=False)

    bottom_xaxis.rangeslider.visible = True


    sleepy_fig.show()
else:
    sleep_survey_long_df = pd.DataFrame(columns=["ID","survey_date","Timestamp","Questions","Value"])
    sleep_survey_long_df["survey_date"] = (
        pd.to_datetime(sleep_survey_long_df["survey_date"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/Detroit")
    )
    sleep_survey_long_df["Timestamp"] = (
        pd.to_datetime(sleep_survey_long_df["Timestamp"], format="%Y-%m-%d_%H%M").dt.tz_localize("America/Detroit")
    )
    display(Markdown(f"_**No Sleep Survey Data Exists**_"))
```

# Merge HR and Sleep Data

```{python}
# | label: Generate merged HR and Sleep dataframe
# | eval: True
# | echo: false
# | warning: false
# | message: false

all_surveys_long_df = (pd.concat(
    [cognitive_survey_long_df, fatigue_survey_long_df, sleep_survey_long_df],
    ignore_index=True,
).sort_values(["survey_date", "Timestamp"]).reset_index(drop=True)
)

max_timestamps = [
    hr_df["TimestampISO"].max(),
    sleep_df["StartISO"].max(),
    gait_df["TimestampISO"].max(),
    double_support_df["TimestampISO"].max(),
    all_surveys_long_df["Timestamp"].max()
]

max_timestamps = [
    timestamp.tz_convert("America/Detroit") if timestamp.tzinfo is not None else timestamp.tz_localize("America/Detroit")
    for timestamp in max_timestamps
    if pd.notna(timestamp)
]

latest_time = max(max_timestamps)

min_timestamps = [
    hr_df["TimestampISO"].min(),
    sleep_df["StartISO"].min(),
    gait_df["TimestampISO"].min(),
    double_support_df["TimestampISO"].min(),
    all_surveys_long_df["Timestamp"].min()
]

min_timestamps = [
    timestamp.tz_convert("America/Detroit") if timestamp.tzinfo is not None else timestamp.tz_localize("America/Detroit")
    for timestamp in max_timestamps
    if pd.notna(timestamp)
]

latest_time = max(max_timestamps)

earliest_time = min(min_timestamps)


time_df = pd.DataFrame(
    {
        "GlobalTime": pd.date_range(start=earliest_time, end=latest_time, freq="30s"),
        "Asleep": "0",
    }
)

mask = time_df["GlobalTime"].apply(
    lambda time: ((sleep_df["StartISO"] <= time) & (sleep_df["EndISO"] >= time)).any()
)

time_df["Asleep"] = mask.astype(int)
time_sorted_df = time_df.sort_values("GlobalTime")
hr_sorted_df = hr_df.sort_values("TimestampISO")

merge_df = pd.merge_asof(
    time_sorted_df,
    hr_sorted_df,
    left_on="GlobalTime",
    right_on="TimestampISO",
    direction="nearest",
    tolerance=pd.Timedelta(seconds=15),
)

new_order = merge_df[["ID", "GlobalTime", "Asleep", "HR"]]
merge_df2 = pd.merge_asof(
    new_order,
    gait_sorted_df[["TimestampISO", "Balance"]],
    left_on="GlobalTime",
    right_on="TimestampISO",
    direction="nearest",
    tolerance=pd.Timedelta(seconds=15),
).drop(columns=["TimestampISO"])

merge_df3 = pd.merge_asof(
    merge_df2,
    double_support_sorted_df[["TimestampISO", "Percentage"]],
    left_on="GlobalTime",
    right_on="TimestampISO",
    direction="nearest",
    tolerance=pd.Timedelta(seconds=15),
)


merge_df4 = pd.merge_asof(
    merge_df3,
    all_surveys_long_df.sort_values("Timestamp"),
    left_on="GlobalTime",
    right_on="Timestamp",
    direction="nearest",
    tolerance=pd.Timedelta(seconds=15),
)

all_data_df = merge_df4.drop(columns=["ID_y"]).rename(columns={"ID_x":"ID"})

all_data_df["ID"] = all_data_df["ID"].ffill().bfill()

```

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

IDs = []
night = []
start = []
end = []
average_hr = []
sd_hr = []
earliest_hr =[]
latest_hr =[]
earliest_timestamp=[]
latest_timestamp = []

sleep_dropped_df = sleep_df.loc[sleep_df["KeepOrDrop"] == 1]

sleep_dropped_df = sleep_dropped_df.sort_values(by="StartISO")

for index, _ in sleep_dropped_df.iterrows():
    ID = sleep_dropped_df["ID"][index]
    start_time  =  sleep_dropped_df["StartISO"][index]
    end_time  =  sleep_dropped_df["EndISO"][index]
    sleep_day = sleep_dropped_df["Night_of_Sleep"][index]
    IDs.append(ID)
    start.append(start_time)
    end.append(end_time)
    night.append(sleep_day)
    #Filter hr_sorted_df to only be included between the start and stop times
    timing_df = hr_sorted_df[(hr_sorted_df["TimestampISO"] >= start_time)]
    timing_df = timing_df[(timing_df["TimestampISO"] <= end_time)]
    
    #Calculate the Mean and standard deviation of the Heart rate during this period (if any heart rate is recorded)
    aveHR = timing_df["HR"].mean()
    std_hr = timing_df["HR"].std()
    
    if len(timing_df) >0:
        first_hr_timestamp = timing_df["TimestampISO"].iloc[0]
        last_hr_timestamp = timing_df["TimestampISO"].iloc[-1]
        first_hr = timing_df["HR"].iloc[0]
        last_hr = timing_df["HR"].iloc[-1]
    else:
        first_hr_timestamp = np.nan
        last_hr_timestamp = np.nan
        first_hr = np.nan
        last_hr = np.nan

    average_hr.append(aveHR)
    sd_hr.append(std_hr)
    earliest_hr.append(first_hr)
    latest_hr.append(last_hr)
    earliest_timestamp.append(first_hr_timestamp)
    latest_timestamp.append(last_hr_timestamp)
    del timing_df
    

hr_dictionary = {
    'ID': IDs,
    'Night_of_Sleep': night,
    'Start_Time': start,
    'End_Time': end,
    'Mean_HR_Present_During_Period':average_hr,
    'Standard_Deviation_of_Present_HR_During Period': sd_hr,
    'Earliest_Recorded_HR': earliest_hr,
    'Earliest_Recorded_HR_Timestamp':earliest_timestamp,
    'Latest_Recorded_HR': latest_hr,
    'Latest_Recorded_HR_Timestamp': latest_timestamp,
}

HR_summary_df = pd.DataFrame(hr_dictionary)

if len(HR_summary_df) <=0:
    empty_row= pd.DataFrame([[pd.NA]*len(HR_summary_df.columns)], columns=HR_summary_df.columns)
    empty_row["ID"] = RID


csv_name = "HR_Summary_"+RID+".csv"

HR_summary_df.dropna(subset=["Night_of_Sleep"]).to_csv(os.path.join(PathKeeper.summarized_data_path,csv_name), index=False)
```

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false

sleep_range_df = sleep_df.copy()
sleep_range_df["Night_of_Sleep"] = pd.to_datetime(sleep_range_df["Night_of_Sleep"], errors="coerce").dt.tz_localize("America/Detroit")

if sleep_range_df.empty or len(sleep_range_df["Night_of_Sleep"]) < 1:
    # Create an empty-but-well-formed output and skip the rest
    sleep_summary_df = pd.DataFrame(columns=["ID", "Day_of_Sleep", "Asleep_Time", "Awake_Time"])
    overall_summary["Days_in_Row_Sleeping_Max"] = np.nan
    overall_summary["Days_in_Row_Sleeping_Min"] = np.nan
    overall_summary["Days_in_Row_Sleeping_Mean"] = np.nan
    overall_summary["Days_in_Row_Sleeping_Median"] = np.nan
    overall_summary["Days_Missing_Sleep"] = np.nan
    overall_summary["Prop_Missing_Sleep"] = np.nan  # or 0, depending on your convention

    csv_name = f"Sleep_Summary_{RID}.csv"
    sleep_summary_df.to_csv(os.path.join(PathKeeper.summarized_data_path, csv_name), index=False)

else:
    night = pd.to_datetime(sleep_df["Night_of_Sleep"], errors="coerce").dt.tz_localize("America/Detroit")

    night = night.dt.normalize()

    earliest_day = night.min()
    latest_day = night.max()

    sleep_days_df = pd.DataFrame({
        "GlobalDay": pd.date_range(
            start=earliest_day,
            end=latest_day,
            freq="1D"
        )
    }
    )

    sleep_df2 = sleep_df.dropna(subset=["Night_of_Sleep"]).copy()


    sleep_df2["Night_of_Sleep"] = pd.to_datetime(sleep_df["Night_of_Sleep"], errors="coerce").dt.tz_localize("America/Detroit")

    sleep_all_df = pd.merge(sleep_days_df, sleep_df2, left_on="GlobalDay", right_on="Night_of_Sleep", how="left").sort_values(["GlobalDay", "StartISO"])

    sleep_all_df["ID"] = sleep_all_df["ID"].fillna(RID)

    sleep_summary_df = pd.DataFrame()

    for date, dataframe in sleep_all_df.groupby("GlobalDay"):
        if dataframe["Duration_in_Minutes"].isna().all():
            dataframe["Asleep_Time"] = pd.NA
            dataframe["AwakeTime"] = pd.NA
            dataframe["Date"] = date
        else:
            dataframe["Asleep_Time"] = dataframe["Duration_in_Minutes"].sum()
            dataframe["Awake_Time"] =  (24*60) -dataframe["Asleep_Time"]
            dataframe["Date"] = date
        sleep_summary_df = pd.concat([sleep_summary_df, dataframe], ignore_index=True) 

    sleep_summary_df = sleep_summary_df[["ID", "GlobalDay", "Asleep_Time", "Awake_Time"]].drop_duplicates("GlobalDay").rename(columns={"GlobalDay":"Day_of_Sleep"})


    sleep_summary_df["Day_of_Sleep"] = pd.to_datetime(sleep_summary_df["Day_of_Sleep"]).dt.date


    sleep_present = sleep_summary_df["Asleep_Time"].notna()

    # Each missing value increases the GroupID
    sleep_summary_df["streak_id"] = (~sleep_present).groupby(sleep_summary_df["ID"]).cumsum()

    # Count number of day that each day is for a given "streak"
    sleep_summary_df["Streak_Length"] = (
        sleep_present.astype(int)
        .groupby([sleep_summary_df["ID"], sleep_summary_df["streak_id"]])
        .cumsum()
    )

    # Replace any "0" with NAN
    sleep_summary_df["Streak_Length"] = sleep_summary_df["Streak_Length"].replace(0, np.nan)

    sleep_streak_length_df = pd.DataFrame()

    #Calculate the maximum number of days for each streak, which would be the streak's
    sleep_streak_length_df["max"] = sleep_summary_df["Streak_Length"].groupby([sleep_summary_df["ID"], sleep_summary_df["streak_id"]]).max()


    overall_summary["Days_in_Row_Sleeping_Max"] = sleep_streak_length_df["max"].max()
    overall_summary["Days_in_Row_Sleeping_Min"] = sleep_streak_length_df["max"].min()
    overall_summary["Days_in_Row_Sleeping_Mean"] = sleep_streak_length_df["max"].mean()
    overall_summary["Days_in_Row_Sleeping_Median"] = sleep_streak_length_df["max"].median()


    overall_summary["Days_Missing_Sleep"] = sleep_summary_df["Asleep_Time"].isnull().sum()

    overall_summary["Prop_Missing_Sleep"] = round(((sleep_summary_df["Asleep_Time"].isnull().sum())/len(sleep_summary_df)),2)


csv_name = "Sleep_Summary_"+RID+".csv"

sleep_summary_df.to_csv(os.path.join(PathKeeper.summarized_data_path,csv_name), index=False)

```

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false


prettify_info(HR_summary_df)

```

```{python}

#| eval: True
#| echo: false
#| warning: false
#| message: false


new_presence_row=pd.DataFrame([{
    "ID": RID,
    "HR_Present": has_hr,
    "Sleep_Present": has_sleep,
    "Double_Support_Present": has_double_support,
    "Asymmetry_Present": has_asymmetry, 
    "Cognitive_Survey_Present": has_cognitive_survey,
    "Fatigue_Survey_Present": has_fatigue_survey,
    "Sleep_Survey_Present": has_sleep_survey
}])


presence_df = pd.concat([presence_df, new_presence_row], ignore_index=True)

presence_df.drop_duplicates(subset=["ID"], keep="last").to_csv(os.path.join(PathKeeper.data_log_path,"Data_Presence_Log.csv"), index=False)

overall_summary_df=pd.DataFrame([overall_summary])
csv_name = "Overall_Summary_"+RID+".csv"
overall_summary_df.to_csv(os.path.join(PathKeeper.summarized_data_path,csv_name), index=False)
```

# All Data Plot

## Faceted Plots

### Non Survey Only

```{python}

#| label: "Physio_Data_Plots"
#| eval: True
#| echo: false
#| warning: false
#| message: false

physio_fig  = make_subplots(rows=4, cols=1, subplot_titles=("HR", "Double Support", "Balance","Sleep Classification"))

add_fig_traces(physio_fig, globals().get("hr_fig"), start_row=1, end_row=1)
add_fig_traces(physio_fig, globals().get("double_support_fig"), start_row=2, end_row=2)
add_fig_traces(physio_fig, globals().get("gait_fig"), start_row=3, end_row=3)
add_fig_traces(physio_fig, globals().get("time_fig"), start_row=4, end_row=4, yaxis_range=[0, None])

physio_fig.update_xaxes(matches="x")
physio_fig.update_xaxes(visible=False, rangeslider_visible=False)
physio_fig.update_xaxes(visible=True, rangeslider_visible=True, row=4, col=1)

physio_fig.update_layout(showlegend=False)
physio_fig.show()



```

### Survey Data

```{python}

#| label: "Survey_Data_Plots"
#| eval: True
#| echo: false
#| warning: false
#| message: false

survey_fig  = make_subplots(rows=10, cols=1, subplot_titles=("Cognitive01", "Cognitive02", "Pain", "Depression","Physical Fatigue","Brain Fatigue","Sleepiness", "Sleep01", "Sleep02", "Sleep03"))

add_fig_traces(survey_fig, globals().get("cog_fig"),     start_row=1, end_row=4)
add_fig_traces(survey_fig, globals().get("fatigue_fig"), start_row=5, end_row=7)
add_fig_traces(survey_fig, globals().get("sleepy_fig"),  start_row=8, end_row=10)

survey_fig.update_xaxes(matches="x")
survey_fig.update_xaxes(visible=False, rangeslider_visible=False)
survey_fig.update_xaxes(visible=True, rangeslider_visible=True, row=10, col=1)
survey_fig.update_layout(showlegend=False)
survey_fig.show()

# new_fig = go.Figure()

# new_fig.add_trace

```

### All Data

```{python}

#| label: "All_Data_Plots"
#| eval: True
#| echo: false
#| warning: false
#| message: false

total_fig  = make_subplots(rows=14, cols=1, subplot_titles=("HR", "Double Support", "Balance", "Sleep Classifications","Cognitive01", "Cognitive02", "Pain", "Depression","Physical Fatigue","Brain Fatigue","Sleepiness", "Sleep01", "Sleep02", "Sleep03"))

add_fig_traces(total_fig, globals().get("hr_fig"), start_row=1, end_row=1)
add_fig_traces(total_fig, globals().get("double_support_fig"), start_row=2, end_row=2)
add_fig_traces(total_fig, globals().get("gait_fig"), start_row=3, end_row=3)
add_fig_traces(total_fig, globals().get("time_fig"), start_row=4, end_row=4, yaxis_range=[0, None])

add_fig_traces(total_fig, globals().get("cog_fig"),     start_row=5, end_row=8)
add_fig_traces(total_fig, globals().get("fatigue_fig"), start_row=9, end_row=11)
add_fig_traces(total_fig, globals().get("sleepy_fig"),  start_row=12, end_row=14)

total_fig.update_xaxes(matches="x")
total_fig.update_xaxes(visible=False, rangeslider_visible=False)
total_fig.update_xaxes(visible=True, rangeslider_visible=True, row=14, col=1)
total_fig.update_layout(showlegend=False)
total_fig.show()

# new_fig = go.Figure()

# new_fig.add_trace

```

## Shared Plot

```{python}
all_traces = []

all_traces += add_traces_single_plot(hr_fig, name_override="Average HR (BPM) from Last Recording",
) if "hr_fig" in globals() else []

all_traces += add_traces_single_plot(time_fig_for_group, name_override="Sleep Stages") if "time_fig_for_group" in globals() else []

all_traces += add_traces_single_plot(double_support_fig, name_override="Double Support Percentage") if "double_support_fig" in globals() else []

all_traces += add_traces_single_plot(gait_fig, name_override="Gait Balance") if "gait_fig" in globals() else []

all_traces += add_traces_single_plot(cog_fig) if "cog_fig" in globals() else []

all_traces += add_traces_single_plot(fatigue_fig) if "fatigue_fig" in globals() else []

all_traces += add_traces_single_plot(sleepy_fig) if "sleepy_fig" in globals() else []

fig = go.Figure(data=all_traces)

fig.update_xaxes(rangeslider_visible=True)

fig.update_layout(title="Shared Plot")
fig.show()
```

### Notices and Metainfo {.unnumbered .unlisted}

#### Copyright {.unnumbered .unlisted}

<details>

<notice>

Copyright © 2025 The Regents of the University of Michigan

This file is part of Yawnalyzer.

This program is free software: you can redistribute it and/or modify

it under the terms of the GNU General Public License as published by

the Free Software Foundation, either version 3 of the License, or (at your option) any later version.

This program is distributed in the hope that it will be useful,

but WITHOUT ANY WARRANTY; without even the implied warranty of

MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the

GNU General Public License for more details.

You should have received a copy of the GNU General Public License along

with this program. If not, see <https://www.gnu.org/licenses/>. </notice>

</details>

#### Session Info {.unnumbered .unlisted}

```{python}

#| label: Session_Information
#| echo: false
#| warning: false
#| message: false

session_info.show()

```